<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Distributed Tensorflow]]></title>
      <url>%2FDistributed-Tensorflow.html</url>
      <content type="text"><![CDATA[原文地址: Distributed TensorFlow 执行简单的TensorFlow集群，执行下面语句：12345678# Start a TensorFlow server as a single-process &quot;cluster&quot;.$ python&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; c = tf.constant(&quot;Hello, distributed TensorFlow!&quot;)&gt;&gt;&gt; server = tf.train.Server.create_local_server()&gt;&gt;&gt; sess = tf.Session(server.target) # Create a session on the server.&gt;&gt;&gt; sess.run(c)&apos;Hello, distributed TensorFlow!&apos; tf.train.Server.create_local_server方法在服务器中创建了一个单一进程的集群。 创建集群TensorFlow集群(cluster)是一组参与TensorFlow分布式图计算的”tasks”。每个task与TensorFlow “server”关联，”server”包含一个用来创建session的master，和一个执行图运算的worker。一个集群可以被分为一个或多个jobs，每个job包含一个或多个tasks。 创建集群需要在每个task中启动TensorFlow server。通常每个task运行在不同的机器上，但也可以在同一台机器上启动多个tasks（如控制不同的GPU设备）。在每个task中，需要： 创建tf.train.ClusterSpec，用来描述集群中的tasks。对于每个task都是相同的。 创建tf.train.Server，在构造函数中传入tf.train.ClusterSpec，用job名和task序号来指定本机的task。 创建tf.train.ClusterSpec描述集群集群用字典来定义：jobs名称对应网络地址列表。把这个字典传入tf.train.ClusterSpec构造器。1tf.train.ClusterSpec(&#123;&quot;local&quot;: [&quot;localhost:2222&quot;, &quot;localhost:2223&quot;]&#125;) /job:local/task:0 /job:local/task:1 12345678910tf.train.ClusterSpec(&#123; &quot;worker&quot;: [ &quot;worker0.example.com:2222&quot;, &quot;worker1.example.com:2222&quot;, &quot;worker2.example.com:2222&quot; ], &quot;ps&quot;: [ &quot;ps0.example.com:2222&quot;, &quot;ps1.example.com:2222&quot; ]&#125;) /job:worker/task:0 /job:worker/task:1 /job:worker/task:2 /job:ps/task:0 /job:ps/task:1 在每个task中创建tf.train.Server实例一个tf.train.Server对象包含一组本地设备，一组与由tf.train.ClusterSpec定义的设备的连接，和一个可以使用这些设备进行分布式计算的tf.Session。每个server都是被命名的job的成员，有自己的task索引号。集群中的一个server可以同其他server进行通信。 例如，要启动运行在localhost:2222和localhost:2223，有两个servers的集群，在本地主机上运行下面的脚本，启动两个不同的进程：123# In task 0:cluster = tf.train.ClusterSpec(&#123;&quot;local&quot;: [&quot;localhost:2222&quot;, &quot;localhost:2223&quot;]&#125;)server = tf.train.Server(cluster, job_name=&quot;local&quot;, task_index=0) 123# In task 1:cluster = tf.train.ClusterSpec(&#123;&quot;local&quot;: [&quot;localhost:2222&quot;, &quot;localhost:2223&quot;]&#125;)server = tf.train.Server(cluster, job_name=&quot;local&quot;, task_index=1) 在模型中指定分布式设备在特定设备上定义运算操作，可以使用相同的tf.device函数，用来指定op在CPU或GPU上运行。123456789101112131415161718with tf.device(&quot;/job:ps/task:0&quot;): weights_1 = tf.Variable(...) biases_1 = tf.Variable(...)with tf.device(&quot;/job:ps/task:1&quot;): weights_2 = tf.Variable(...) biases_2 = tf.Variable(...)with tf.device(&quot;/job:worker/task:7&quot;): input, labels = ... layer_1 = tf.nn.relu(tf.matmul(input, weights_1) + biases_1) logits = tf.nn.relu(tf.matmul(layer_1, weights_2) + biases_2) # ... train_op = ...with tf.Session(&quot;grpc://worker7.example.com:2222&quot;) as sess: for _ in range(10000): sess.run(train_op) 在上面的例子中，变量是在psjob中的两个task里被创建，而模型的运算部分是在workerjob中被创建。TensorFlow会在jobs之间进行数据传输（从ps传到worker是前向计算，从worker到’ps’是应用梯度）。 复制训练一种常见的训练配置，称为“数据并行”，在workerjob的多个tasks中使用不同的mini-batches训练相同的模型，在一个或多个psjob上更新共享的参数。所有的tasks可以运行在不同的机器上。TensorFlow中有多种方法可以定义这样的结构，我们正在构建多个库，将用于简化构建复制的模型的工作。现有的方法包括： 图内复制（in-graph replication） 这种方法中，client建立单一的tf.Graph，图中既有创建在/job:ps上的tf.Variable等变量的集合，也有在job：worker上的模型的计算部分的多个副本。 图间复制（between-graph replication） 每个/job:workertask有其独立的client，通常运行在worker task相同的进程中。每个client建立包含参数的相似的图（参数原本在/job:ps上，通过使用tf.train.replica_device_setter复制到task）；和在本地task/job:worker上的模型计算部分的一个副本。 异步训练（asynchronous trainng） 每个图的副本进行独立的训练，不与其他图协同。它与上述两种复制形式兼容。 同步训练（synchronous training） 所有副本读取当前参数的值，并行计算梯度，然后共同应用梯度更新参数。兼容图内复制（如使用平均梯度，CIFAR-10 多GPU训练），兼容图间复制（如使用tf.train.SyncReplicasOptimizer) 训练程序示例下面是一个分布式训练程序，实现了图间复制和同步训练：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import argparseimport sysimport tensorflow as tfFLAGS = Nonedef main(_): ps_hosts = FLAGS.ps_hosts.split(&quot;,&quot;) worker_hosts = FLAGS.worker_hosts.split(&quot;,&quot;) # Create a cluster from the parameter server and worker hosts. cluster = tf.train.ClusterSpec(&#123;&quot;ps&quot;: ps_hosts, &quot;worker&quot;: worker_hosts&#125;) # Create and start a server for the local task. server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index) if FLAGS.job_name == &quot;ps&quot;: server.join() elif FLAGS.job_name == &quot;worker&quot;: # Assigns ops to the local worker by default. with tf.device(tf.train.replica_device_setter( worker_device=&quot;/job:worker/task:%d&quot; % FLAGS.task_index, cluster=cluster)): # Build model... loss = ... global_step = tf.contrib.framework.get_or_create_global_step() train_op = tf.train.AdagradOptimizer(0.01).minimize( loss, global_step=global_step) # The StopAtStepHook handles stopping after running given steps. hooks=[tf.train.StopAtStepHook(last_step=1000000)] # The MonitoredTrainingSession takes care of session initialization, # restoring from a checkpoint, saving to a checkpoint, and closing when done # or an error occurs. with tf.train.MonitoredTrainingSession(master=server.target, is_chief=(FLAGS.task_index == 0), checkpoint_dir=&quot;/tmp/train_logs&quot;, hooks=hooks) as mon_sess: while not mon_sess.should_stop(): # Run a training step asynchronously. # See `tf.train.SyncReplicasOptimizer` for additional details on how to # perform *synchronous* training. # mon_sess.run handles AbortedError in case of preempted PS. mon_sess.run(train_op)if __name__ == &quot;__main__&quot;: parser = argparse.ArgumentParser() parser.register(&quot;type&quot;, &quot;bool&quot;, lambda v: v.lower() == &quot;true&quot;) # Flags for defining the tf.train.ClusterSpec parser.add_argument( &quot;--ps_hosts&quot;, type=str, default=&quot;&quot;, help=&quot;Comma-separated list of hostname:port pairs&quot; ) parser.add_argument( &quot;--worker_hosts&quot;, type=str, default=&quot;&quot;, help=&quot;Comma-separated list of hostname:port pairs&quot; ) parser.add_argument( &quot;--job_name&quot;, type=str, default=&quot;&quot;, help=&quot;One of &apos;ps&apos;, &apos;worker&apos;&quot; ) # Flags for defining the tf.train.Server parser.add_argument( &quot;--task_index&quot;, type=int, default=0, help=&quot;Index of task within the job&quot; ) FLAGS, unparsed = parser.parse_known_args() tf.app.run(main=main, argv=[sys.argv[0]] + unparsed) 使用两个servers和两个workers启动训练，执行下面的脚本：1234567891011121314151617181920# On ps0.example.com:$ python trainer.py \ --ps_hosts=ps0.example.com:2222,ps1.example.com:2222 \ --worker_hosts=worker0.example.com:2222,worker1.example.com:2222 \ --job_name=ps --task_index=0# On ps1.example.com:$ python trainer.py \ --ps_hosts=ps0.example.com:2222,ps1.example.com:2222 \ --worker_hosts=worker0.example.com:2222,worker1.example.com:2222 \ --job_name=ps --task_index=1# On worker0.example.com:$ python trainer.py \ --ps_hosts=ps0.example.com:2222,ps1.example.com:2222 \ --worker_hosts=worker0.example.com:2222,worker1.example.com:2222 \ --job_name=worker --task_index=0# On worker1.example.com:$ python trainer.py \ --ps_hosts=ps0.example.com:2222,ps1.example.com:2222 \ --worker_hosts=worker0.example.com:2222,worker1.example.com:2222 \ --job_name=worker --task_index=1 ##术语 clientclient指一个程序，构建TensorFlow图和TensorFlow Session与集群进行交互。一个client进程可以与多个TensorFlow服务器进行交互（见上面的章节），一个服务器上也可以运行多个client程序。 cluster一个TensorFlow集群包含一个或多个”jobs”，每个”job“可以分成一个或多个”tasks”。集群通常专用于特定的高级目标，如训练神经网络，并行使用许多机器。一个集群由tf.train.ClusterSpec对象指定。 job一个job由”tasks”列表组成，这些tasks通常用于相同的目的。例如，名为ps（参数服务器 parameter server）的job，通常保存、更新参数的节点；而名为worker的job通常承载承载执行计算密集型任务的无状态节点。一个job中的tasks通常运行在不同机器上。 task一个task代表一个特定的TensorFlow服务器，通常对应一个进程。一个task属于一个job，用该job的tasks列表的下标来区分。 TensorFlow server运行tf.train.Server实例的进程，是集群的一个成员。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TensorFlow运行多个计算图]]></title>
      <url>%2FTensorFlow%E8%BF%90%E8%A1%8C%E5%A4%9A%E4%B8%AA%E8%AE%A1%E7%AE%97%E5%9B%BE.html</url>
      <content type="text"><![CDATA[有这样的需求：在同一个程序中需要运行两个训练好的TensorFlow模型。如果仅仅是把两个模型放到两个类中，简单的把两个类的代码组合到一起，会出现问题。 这是由于TensorFlow的运行基于计算图(Graph)，在代码中不明确指定当前所用的图的情况下，TensorFlow会自动创建一个图，作为当前的默认图。创建的所有Tensor和计算(op)都会添加到当前默认图中。 而TensorFlow的会话(Session)也是需要基于图来创建，tf.Session()可以通过graph参数来指定Session运行于哪个图上。 当在不明确指定图的情况下，创建两个模型时，两个模型会在同一张图中，可能会出现变量名相同、变量形状不匹配、Session不能启动等问题。 解决方法是在每个模型中自行定义所使用的图，并在向图中添加Tensor和op时将该模型的图作为默认图，在启动Session时指定运行图为当前的图。例如两个模型分别封装在两个类中 在创建类时，定义变量self.graph = tf.Graph() 在定义网络结构时，在每个Tensor和op前添加with self.graph.as_default(): 运行Session时，传入当前的图：self.sess = tf.Session(graph=self.graph) 这样，定义模型结构和运行会话都分别在两个图中进行，不会产生冲突。 参考资料： http://blog.csdn.net/xierhacker/article/details/53860379 https://stackoverflow.com/questions/42593771/session-graph-is-empty]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TensorFlow DataSet API的一个问题]]></title>
      <url>%2FTensorFlow-DataSet-API%E7%9A%84%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98.html</url>
      <content type="text"><![CDATA[在使用TensorFlow新的DataSet API时遇到了一个坑。 123batched_dataset = dataset.batch(4)iterator = batched_dataset.make_one_shot_iterator()next_element = iterator.get_next() DataSet.batch(batch_size)会返回一个第一个维度为batch_size大小的Tensor。但当不断调用interator.get_next()，遍历到样本集的末端时，返回的Tensor的大小可能不为batch_size。 例如样本集中有17个元素，batch_size为4时，第5次调用iterator.get_next()只能返回大小为1的batch。 DataSet.repeat()会返回一个无限重复原数据集的DataSet对象，当调用了repeat()时，也会产生上面的问题，有问题代码如下：123456789101112def read_batch(self, batch_size=None, shuffle_buffer=None, repeat=None): dataset = tf.contrib.data.TFRecordDataset(self._files) dataset = dataset.map(self.__parse_function) if batch_size: dataset = dataset.batch(batch_size) if shuffle_buffer: dataset = dataset.shuffle(buffer_size=shuffle_buffer) if repeat != 0: dataset = dataset.repeat(repeat) iterator = dataset.make_one_shot_iterator() batch_data = iterator.get_next() return self._extract_batch(batch_data) 在遍历数据集的最后一个batch的大小不为batch_size。 在stackoverflow找到了类似的问题：returned size of tensorflow’s dataset API is not constant 解决方法为：在batch()之前调用repeat() …… …… 123456789101112def read_batch(self, batch_size=None, shuffle_buffer=None, repeat=None): dataset = tf.contrib.data.TFRecordDataset(self._files) dataset = dataset.map(self.__parse_function) if shuffle_buffer: dataset = dataset.shuffle(buffer_size=shuffle_buffer) if repeat != 0: dataset = dataset.repeat(repeat) if batch_size: dataset = dataset.batch(batch_size) iterator = dataset.make_one_shot_iterator() batch_data = iterator.get_next() return self._extract_batch(batch_data)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TensorFlow学习笔记：Importing Data]]></title>
      <url>%2FTensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9AImporting-Data.html</url>
      <content type="text"><![CDATA[DatasetAPI可使你从简单、可重用的片段构建复杂的输入管道。例如，一个图像模型的输入管道可能从分布式的系统中聚合数据，对每个图像进行随机扰动，并随机选择一批图像用于训练；文本模型的输入管道可能从原始的文本中提取特征，利用查找表将其转化为embedding identifiers，并将不同长度的序列组合在一起。DatasetAPI可以很容易的处理大量数据、不同数据格式和复杂的变换。 DatasetAPI引入了两个抽象概念： 一个tf.contrib.data.Dataset代表一个元素序列，每个元素包含一个或多个Tensor对象。例如图像管道中，一个元素可能是包含一对表示图像数据和类别标签的Tensor的单一训练样本。有两种创建dataset的方式： 创建source（如Dataset.from_tensor_slices()），由一个或多个tf.Tensor对象构建一个dataset。 应用transformation（如Dataset.batch()），从一个或多个tf.contrib.data.Dataset对象中创建新dataset。 一个tf.contrib.data.Iterator提供从dataset提取元素的方法。Iterator.get_next()返回的op执行时产生Dataset的下一个元素，这通常作为输入管道和模型之间的接口。最简单的迭代器是”one-shot 迭代器”，它与一个特定的Dataset相关联，作一次性遍历。Iterator.initializerop能够让你用不同的数据集再初始化和参数化一个迭代器，这样你可以在相同的程序中多次迭代训练集/验证集数据。 基本机制这一节讲了创建不同种类的Dataset和Iterator对象的基本方法，和如何从其中提取数据。 启动输入管道前，必须定义一个source。例如，从内存中的一些Tensor中创建一个Dataset，可使用tf.contrib.data.Dataset.from_tensors()或tf.contrib.data.Dataset.from_tensor_slices()。如果你的输入数据来自磁盘中的TFRecord，使用tf.contrib.data.TFRecordDataset。 一旦有了Dataset对象，可以transform它，调用链接方法生成新的Dataset。例如，可以应用每元变换（per-element transformations）如Dataset.map()，和多元变换（multi-element transformations）如Dataset.batch()。查看tf.contrib.data.Dataset文档了解所有的变换方法。 从Dataset中取值最常见的方法是通过iterator对象每次获取数据集中的一个元素（如调用Dataset.make_one_shot_iterator）。tf.contrib.data.Iterator对象提供两种运算：Iterator.initializer可（再）初始化迭代器的状态；Iterator.get_next()返回下一个元素的Tensor对象。取决于你的应用，可以选择不同类型的迭代器，概述如下。 数据集结构一个dataset包含的每个元素都有相同的结构。每个元素包含一个或多个tf.Tensor对象，称为component。每个component的tf.DType代表tensor中元素的类型，tf.TensorShape代表每个元素的固定的形状（可能只指定一部分维度）。Dataset.output_types和Dataset.output_shapes属性使你能对推断出的数据集元素的类型和形状进行检查。这种属性的嵌套结构对应元素的结构，元素可以是单个Tensor，Tensor元组或嵌套的Tensor元组，例如：12345678910111213dataset1 = tf.contrib.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))print(dataset1.output_types) # ==&gt; "tf.float32"print(dataset1.output_shapes) # ==&gt; "(10,)"dataset2 = tf.contrib.data.Dataset.from_tensor_slices( (tf.random_uniform([4]), tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)))print(dataset2.output_types) # ==&gt; "(tf.float32, tf.int32)"print(dataset2.output_shapes) # ==&gt; "((), (100,))"dataset3 = tf.contrib.data.Dataset.zip((dataset1, dataset2))print(dataset3.output_types) # ==&gt; (tf.float32, (tf.float32, tf.int32))print(dataset3.output_shapes) # ==&gt; "(10, ((), (100,)))" 给元素的每个component命名很方便，如果不同的component表示训练样本的不同的特征。除了使用元组之外，还可以用collections.namedtuple或一个{string : tensor}的字典表示数据集的一个元素。12345dataset = tf.contrib.data.Dataset.from_tensor_slices( &#123;"a": tf.random_uniform([4]), "b": tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)&#125;)print(dataset.output_types) # ==&gt; "&#123;'a': tf.float32, 'b': tf.int32&#125;"print(dataset.output_shapes) # ==&gt; "&#123;'a': (), 'b': (100,)&#125;" Dataset变换支持任何结构的数据集。当使用Dataset.map()，Dataset.flat_map()和Dataset.filter()变换时，需要根据元素的结构来定义这些函数的参数：123456dataset1 = dataset1.map(lambda x: ...)dataset2 = dataset2.flat_map(lambda x, y: ...)# Note: Argument destructuring is not available in Python 3.dataset3 = dataset3.filter(lambda x, (y, z): ...) 创建迭代器你已经创建了表示输入数据的Dataset，下一步就是创建一个Iterator来获取数据集中的元素。DatasetAPI目前支持三种迭代器： one-shot initializable reinitializable 和 feedable one shot 迭代器是最简单的形式，只支持一次性遍历数据集，不需要显式的初始化操作。当前绝大多数基于队列的输入管道所支持的情况它都能处理，但不支持参数化。1234567dataset = tf.contrib.data.Dataset.range(100)iterator = dataset.make_one_shot_iterator()next_element = iterator.get_next()for i in range(100): value = sess.run(next_element) assert i == value initializable 迭代器需要在使用前显示的定义iterator.initializer。可以根据数据集对迭代器操作进行参数化，可在初始化时使用tf.placeholder()Tensor作为feed。12345678910111213141516max_value = tf.placeholder(tf.int64, shape=[])dataset = tf.contrib.data.Dataset.range(max_value)iterator = dataset.make_initializable_iterator()next_element = iterator.get_next()# Initialize an iterator over a dataset with 10 elements.sess.run(iterator.initializer, feed_dict=&#123;max_value: 10&#125;)for i in range(10): value = sess.run(next_element) assert i == value# Initialize the same iterator over a dataset with 100 elements.sess.run(iterator.initializer, feed_dict=&#123;max_value: 100&#125;)for i in range(100): value = sess.run(next_element) assert i == value reinitializable 迭代器可以以多个不同的Dataset对象进行初始化。例如，你可能有一个这样的训练集输入管道：对输入的图像进行随机扰动，和用于在原始图像进行评估的验证集输入管道。这两个管道使用不同的Dataset对象，但是它们的结构是相同的（每个component有相同类型和兼容的形状）。123456789101112131415161718192021222324252627# Define training and validation datasets with the same structure.training_dataset = tf.contrib.data.Dataset.range(100).map( lambda x: x + tf.random_uniform([], -10, 10, tf.int64))validation_dataset = tf.contrib.data.Dataset.range(50)# A reinitializable iterator is defined by its structure. We could use the# `output_types` and `output_shapes` properties of either `training_dataset`# or `validation_dataset` here, because they are compatible.iterator = Iterator.from_structure(training_dataset.output_types, training_dataset.output_shapes)next_element = iterator.get_next()training_init_op = iterator.make_initializer(training_dataset)validation_init_op = iterator.make_initializer(validation_dataset)# Run 20 epochs in which the training dataset is traversed, followed by the# validation dataset.for _ in range(20): # Initialize an iterator over the training dataset. sess.run(training_init_op) for _ in range(100): sess.run(next_element) # Initialize an iterator over the validation dataset. sess.run(validation_init_op) for _ in range(50): sess.run(next_element) feedable 迭代器可以在调用tf.Session.run时和tf.placeholder一起使用，通过feed_dict机制，以选择使用哪种Iterator。它与reinitializable迭代器有相同的功能，但在你切换迭代器时不需要从数据集的开始初始化迭代器。举例：使用和上面例子相同的训练和验证样本，可以使用tf.contrib.data.Iterator.from_string_handle来定义一个feedable迭代器，用来在两个数据集间切换。123456789101112131415161718192021222324252627282930313233343536# Define training and validation datasets with the same structure.training_dataset = tf.contrib.data.Dataset.range(100).map( lambda x: x + tf.random_uniform([], -10, 10, tf.int64)).repeat()validation_dataset = tf.contrib.data.Dataset.range(50)# A feedable iterator is defined by a handle placeholder and its structure. We# could use the `output_types` and `output_shapes` properties of either# `training_dataset` or `validation_dataset` here, because they have# identical structure.handle = tf.placeholder(tf.string, shape=[])iterator = tf.contrib.data.Iterator.from_string_handle( handle, training_dataset.output_types, training_dataset.output_shapes)next_element = iterator.get_next()# You can use feedable iterators with a variety of different kinds of iterator# (such as one-shot and initializable iterators).training_iterator = training_dataset.make_one_shot_iterator()validation_iterator = validation_dataset.make_initializable_iterator()# The `Iterator.string_handle()` method returns a tensor that can be evaluated# and used to feed the `handle` placeholder.training_handle = sess.run(training_iterator.string_handle())validation_handle = sess.run(validation_iterator.string_handle())# Loop forever, alternating between training and validation.while True: # Run 200 steps using the training dataset. Note that the training dataset is # infinite, and we resume from where we left off in the previous `while` loop # iteration. for _ in range(200): sess.run(next_element, feed_dict=&#123;handle: training_handle&#125;) # Run one pass over the validation dataset. sess.run(validation_iterator.initializer) for _ in range(50): sess.run(next_element, feed_dict=&#123;handle: validation_handle&#125;) 从迭代器中取值Iterator.get_next()方法返回一个或多个Tensor对象，对应迭代器的下一个元素。每次这些Tensor被求值时，它们从底层的数据集中取下一个元素的值。（注意：同其他具有状态的对象相似，调用Iterator.get_next()不会立即执行，你必须在tf.Session.run中传递其返回的Tensor对象的相应表达式，才会取得下一个元素并推进迭代器。） 如果迭代器到达数据集的末端，执行Iterator.get_next()会产生tf.errors.OutOfRangeError。之后迭代器会变成不可用状态，如果想再次使用必须对其重新初始化。123456789101112131415161718dataset = tf.contrib.data.Dataset.range(5)iterator = dataset.make_initializable_iterator()next_element = iterator.get_next()# Typically `result` will be the output of a model, or an optimizer's# training operation.result = tf.add(next_element, next_element)sess.run(iterator.initializer)print(sess.run(result)) # ==&gt; "0"print(sess.run(result)) # ==&gt; "2"print(sess.run(result)) # ==&gt; "4"print(sess.run(result)) # ==&gt; "6"print(sess.run(result)) # ==&gt; "8"try: sess.run(result)except tf.errors.OutOfRangeError: print("End of dataset") # ==&gt; "End of dataset" 常见的形式是在try-except里进行训练循环：123456sess.run(iterator.initializer)while True: try: sess.run(result) except tf.errors.OutOfRangeError: break 如果数据集中的每个元素都是嵌套结构，Iterator.get_next()返回的一个或多个Tensor也是这种相同的嵌套结构：12345678dataset1 = tf.contrib.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))dataset2 = tf.contrib.data.Dataset.from_tensor_slices((tf.random_uniform([4]), tf.random_uniform([4, 100])))dataset3 = tf.contrib.data.Dataset.zip((dataset1, dataset2))iterator = dataset3.make_initializable_iterator()sess.run(iterator.initializer)next1, (next2, next3) = iterator.get_next() 注意对next1,next2或next3任意一个求值都会推进迭代器，典型的迭代器取值的做法是在一个表达式中包含其所有component。 读输入数据Numpy 数组如果全部输入数据都在内存中，最简单的方式是由其创建Dataset，转化为tf.Tensor，使用Dataset.from_tensor_slices()123456789# Load the training data into two NumPy arrays, for example using `np.load()`.with np.load("/var/data/training_data.npy") as data: features = data["features"] labels = data["labels"]# Assume that each row of `features` corresponds to the same row as `labels`.assert features.shape[0] == labels.shape[0]dataset = tf.contrib.data.Dataset.from_tensor_slices((features, labels)) 上面的代码会以tf.constant()op在TensorFlow计算图种表示features和labels数组。这适合小的数据集，但是很浪费内存，因为数组的内容会被复制多次，可能会超出tf.GraphDef定义的protocol buffer的2GB大小限制。 作为替代方案，可以以tf.placeholder()Tensor的形式定义Dataset，在迭代器初始化时 feed Numpy 数组。123456789101112131415161718# Load the training data into two NumPy arrays, for example using `np.load()`.with np.load("/var/data/training_data.npy") as data: features = data["features"] labels = data["labels"]# Assume that each row of `features` corresponds to the same row as `labels`.assert features.shape[0] == labels.shape[0]features_placeholder = tf.placeholder(features.dtype, features.shape)labels_placeholder = tf.placeholder(labels.dtype, labels.shape)dataset = tf.contrib.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))# [Other transformations on `dataset`...]dataset = ...iterator = dataset.make_initializable_iterator()sess.run(iterator.initializer, feed_dict=&#123;features_placeholder: features, labels_placeholder: labels&#125;) TFRecord 数据DatasetAPI支持多种文件格式类型，所以你可以处理不能完整读入内存的大的数据集。以TFRecord为例，TFRecord是一种面向记录的二进制文件，很多TensorFlow应用使用它作为训练数据。tf.contrib.data.TFRecordDataset能够使TFRecord文件作为输入管道的输入流。123# Creates a dataset that reads all of the examples from two files.filenames = ["/var/data/file1.tfrecord", "/var/data/file2.tfrecord"]dataset = tf.contrib.data.TFRecordDataset(filenames) 传递给TFRecordDataset的参数filenames可以是字符串，字符串列表或tf.Tensor类型的字符串。因此，如果有两组文件分别作为训练和验证，可以使用tf.placeholder(tf.string)来表示文件名，使用适当的文件名来初始化一个迭代器。1234567891011121314151617filenames = tf.placeholder(tf.string, shape=[None])dataset = tf.contrib.data.TFRecordDataset(filenames)dataset = dataset.map(...) # Parse the record into tensors.dataset = dataset.repeat() # Repeat the input indefinitely.dataset = dataset.batch(32)iterator = dataset.make_initializable_iterator()# You can feed the initializer with the appropriate filenames for the current# phase of execution, e.g. training vs. validation.# Initialize `iterator` with training data.training_filenames = ["/var/data/file1.tfrecord", "/var/data/file2.tfrecord"]sess.run(iterator.initializer, feed_dict=&#123;filenames: training_filenames&#125;)# Initialize `iterator` with validation data.validation_filenames = ["/var/data/validation1.tfrecord", ...]sess.run(iterator.initializer, feed_dict=&#123;filenames: validation_filenames&#125;) ###文本数据很多数据集是一个或多个文本文件。tf.contrib.data.TextLineDataset提供了一种简单的方式来提取这些文件的每一行。给定一个或多个文件名，TextLineDataset会对这些文件的每行生成一个值为字符串的元素。TextLineDataset也可以接受tf.Tensor作为filenames，所以你可以传递一个tf.placeholder(tf.string)作为参数。12filenames = ["/var/data/file1.txt", "/var/data/file2.txt"]dataset = tf.contrib.data.TextLineDataset(filenames) 默认下，TextLineDataset生成每个文件中的每一行，这可能不是你所需要的，例如文件中有标题行，或包含注释。可以使用Dataset.skip()和Dataset.filter()来剔除这些行。为了对每个文件都各自应用这些变换，使用Dataset.flat_map()来对每个文件创建一个嵌套的Dataset12345678910111213filenames = ["/var/data/file1.txt", "/var/data/file2.txt"]dataset = tf.contrib.data.Dataset.from_tensor_slices(filenames)# Use `Dataset.flat_map()` to transform each file as a separate nested dataset,# and then concatenate their contents sequentially into a single "flat" dataset.# * Skip the first line (header row).# * Filter out lines beginning with "#" (comments).dataset = dataset.flat_map( lambda filename: ( tf.contrib.data.TextLineDataset(filename) .skip(1) .filter(lambda line: tf.not_equal(tf.substr(line, 0, 1), "#")))) 使用Dataset.map()进行数据预处理Dataset.map(f)变换对每个元素应用给定的函数f生成一个新的dataset。这个函数基于函数式编程中通用的map()函数，应用于列表型的数据结构。函数f接受代表单个元素的tf.Tensor作为输入，返回tf.Tensor对象作为新数据集中的元素。在实现上，使用了标准的TensorFlow op将一个元素转换为另一个。 这一节介绍了使用Dataset.map()的例子。 解析tf.Example protocol buffer很多输入管道从TFRecord格式的文件中提取tf.train.Example protocol buffer。每个tf.train.Example记录包含一个或多个features，输入管道把这些featrues转换成Tensor。12345678910111213# Transforms a scalar string `example_proto` into a pair of a scalar string and# a scalar integer, representing an image and its label, respectively.def _parse_function(example_proto): features = &#123;"image": tf.FixedLenFeature((), tf.string, default_value=""), "label": tf.FixedLenFeature((), tf.int32, default_value=0)&#125; parsed_features = tf.parse_single_example(example_proto, features) return parsed_features["image"], parsed_features["label"]# Creates a dataset that reads all of the examples from two files, and extracts# the image and label features.filenames = ["/var/data/file1.tfrecord", "/var/data/file2.tfrecord"]dataset = tf.contrib.data.TFRecordDataset(filenames)dataset = dataset.map(_parse_function) 解码图像、调整大小利用真实世界的图像数据训练神经网络时，通常需要把不同大小的图像转换为常见的尺寸，这样可以组织为一批固定大小的数据。12345678910111213141516# Reads an image from a file, decodes it into a dense tensor, and resizes it# to a fixed shape.def _parse_function(filename, label): image_string = tf.read_file(filename) image_decoded = tf.image.decode_image(image_string) image_resized = tf.image.resize_images(image_decoded, [28, 28]) return image_resized, label# A vector of filenames.filenames = tf.constant(["/var/data/image1.jpg", "/var/data/image2.jpg", ...])# `labels[i]` is the label for the image in `filenames[i].labels = tf.constant([0, 37, ...])dataset = tf.contrib.data.Dataset.from_tensor_slices((filenames, labels))dataset = dataset.map(_parse_function) 使用tf.py_func()应用Python逻辑为了提高性能，我们鼓励你使用TensorFlow中的操作进行数据预处理。但有时使用内置的Python库来解析输入数据也有效。12345678910111213141516171819202122import cv2# Use a custom OpenCV function to read the image, instead of the standard# TensorFlow `tf.read_file()` operation.def _read_py_function(filename, label): image_decoded = cv2.imread(image_string, cv2.IMREAD_GRAYSCALE) return image_decoded, label# Use standard TensorFlow operations to resize the image to a fixed shape.def _resize_function(image_decoded, label): image_decoded.set_shape([None, None, None]) image_resized = tf.image.resize_images(image_decoded, [28, 28]) return image_resized, labelfilenames = ["/var/data/image1.jpg", "/var/data/image2.jpg", ...]labels = [0, 37, 29, 1, ...]dataset = tf.contrib.data.Dataset.from_tensor_slices((filenames, labels))dataset = dataset.map( lambda filename, label: tf.py_func( _read_py_function, [filename, label], [tf.uint8, label.dtype]))dataset = dataset.map(_resize_function) 输出Batch简单的Batching最简单的形式是堆叠n个连续的数据集元素，组织成一个单一的元素。Dataset.batch()变换正是这么做的。和tf.stack()具有相同的限制条件，对每个元素、每个component的Tensor都必须有相同的形状。1234567891011inc_dataset = tf.contrib.data.Dataset.range(100)dec_dataset = tf.contrib.data.Dataset.range(0, -100, -1)dataset = tf.contrib.data.Dataset.zip((inc_dataset, dec_dataset))batched_dataset = dataset.batch(4)iterator = batched_dataset.make_one_shot_iterator()next_element = iterator.get_next()print(sess.run(next_element)) # ==&gt; ([0, 1, 2, 3], [ 0, -1, -2, -3])print(sess.run(next_element)) # ==&gt; ([4, 5, 6, 7], [-4, -5, -6, -7])print(sess.run(next_element)) # ==&gt; ([8, 9, 10, 11], [-8, -9, -10, -11]) 带边距的Batching Tensors上面的方法可以处理相同形状的Tensor。但是很多模型的输入数据的大小不一（如长度不同的序列）。为了处理这个情况，Dataset.padded_batch()变换可以对某些维度指定边距，以处理不同形状的Tensor。123456789101112dataset = tf.contrib.data.Dataset.range(100)dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))dataset = dataset.padded_batch(4, padded_shapes=[None])iterator = dataset.make_one_shot_iterator()next_element = iterator.get_next()print(sess.run(next_element)) # ==&gt; [[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]]print(sess.run(next_element)) # ==&gt; [[4, 4, 4, 4, 0, 0, 0], # [5, 5, 5, 5, 5, 0, 0], # [6, 6, 6, 6, 6, 6, 0], # [7, 7, 7, 7, 7, 7, 7]] Dataset.padded_batch()变换允许你对每一个component的每一维度设置不同的边距，边距也可以是可变的长度（设置为None，参考上面的例子），也可以为边距赋值，默认为0。 训练流程处理多轮epochDatasetAPI提供了两种处理多轮相同数据的方法。 迭代一个数据集多次最简单的方法是使用Dataset.repeat()变换。下面的例子是创建一个数据集来重复输入10个epochs：12345filenames = ["/var/data/file1.tfrecord", "/var/data/file2.tfrecord"]dataset = tf.contrib.data.TFRecordDataset(filenames)dataset = dataset.map(...)dataset = dataset.repeat(10)dataset = dataset.batch(32) 不带参数的Dataset.repeat()会无限的重复输入。Dataset.repeat()变换不会提示一个epoch的结束或新的epoch的开始。 如果想接收epoch起始或结束的信号，可以写一个训练循环，在每个数据集结束时捕获tf.errors.OutOfRangeError，在每轮结束时可以计算一些统计量（如验证集错误率）1234567891011121314151617filenames = ["/var/data/file1.tfrecord", "/var/data/file2.tfrecord"]dataset = tf.contrib.data.TFRecordDataset(filenames)dataset = dataset.map(...)dataset = dataset.batch(32)iterator = dataset.make_initializable_iterator()next_element = iterator.get_next()# Compute for 100 epochs.for _ in range(100): sess.run(iterator.initializer) while True: try: sess.run(next_element) except tf.errors.OutOfRangeError: break # [Perform end-of-epoch calculations here.] 随机打乱数据Dataset.shuffle()变换使用类似tf.RandomShuffleQueue的算法来随机打乱输入数据：其内部有固定长度的缓冲区，并从该缓冲区中随机的选择下一个元素。123456filenames = ["/var/data/file1.tfrecord", "/var/data/file2.tfrecord"]dataset = tf.contrib.data.TFRecordDataset(filenames)dataset = dataset.map(...)dataset = dataset.shuffle(buffer_size=10000)dataset = dataset.batch(32)dataset = dataset.repeat() 使用高级APItf.train.MonitoredTrainingSessionAPI在分布式的设置下在很多方面简化运行TensorFlow。MonitoredTrainSession使用tf.errors.OutOfRangeError来标志训练完成，如果和DatasetAPI一起用的话，推荐使用Dataset.make_one_shot_iterator()。12345678910111213141516filenames = ["/var/data/file1.tfrecord", "/var/data/file2.tfrecord"]dataset = tf.contrib.data.TFRecordDataset(filenames)dataset = dataset.map(...)dataset = dataset.shuffle(buffer_size=10000)dataset = dataset.batch(32)dataset = dataset.repeat(num_epochs)iterator = dataset.make_one_shot_iterator()next_example, next_label = iterator.get_next()loss = model_function(next_example, next_label)training_op = tf.train.AdagradOptimizer(...).minimize(loss)with tf.train.MonitoredTrainingSession(...) as sess: while not sess.should_stop(): sess.run(training_op) 如果把Dataset作为tf.estimator.Estimator的input_fn来使用，也推荐用Dataset.make_one_shot_iterator12345678910111213141516171819202122232425262728293031323334def dataset_input_fn(): filenames = ["/var/data/file1.tfrecord", "/var/data/file2.tfrecord"] dataset = tf.contrib.data.TFRecordDataset(filenames) # Use `tf.parse_single_example()` to extract data from a `tf.Example` # protocol buffer, and perform any additional per-record preprocessing. def parser(record): keys_to_features = &#123; "image_data": tf.FixedLenFeature((), tf.string, default_value=""), "date_time": tf.FixedLenFeature((), tf.int64, default_value=""), "label": tf.FixedLenFeature((), tf.int64, default_value=tf.zeros([], dtype=tf.int64)), &#125; parsed = tf.parse_single_example(record, keys_to_features) # Perform additional preprocessing on the parsed data. image = tf.decode_jpeg(parsed["image_data"]) image = tf.reshape(image, [299, 299, 1]) label = tf.cast(parsed["label"], tf.int32) return &#123;"image_data": image, "date_time": parsed["date_time"]&#125;, label # Use `Dataset.map()` to build a pair of a feature dictionary and a label # tensor for each example. dataset = dataset.map(parser) dataset = dataset.shuffle(buffer_size=10000) dataset = dataset.batch(32) dataset = dataset.repeat(num_epochs) iterator = dataset.make_one_shot_iterator() # `features` is a dictionary in which each value is a batch of values for # that feature; `labels` is a batch of labels. features, labels = iterator.get_next() return features, labels]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LaTeX数学公式符号]]></title>
      <url>%2FLaTeX%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E7%AC%A6%E5%8F%B7.html</url>
      <content type="text"><![CDATA[角标 上标 ^{} 下标 _{} 角标为单个字符时，可以不用{}；角标为多字符或多层次，必须使用{} x^2 $x^2$ x^2_1 $x^2_1$ x^{(n)}_{22} $x^{(n)}_{22}$ ^{16}O^{2-}_{32}$^{16}O^{2-}_{32}$ x^{y_z} $x^{y_z}$ 分式 \frac{分子}{分母} \frac{x+y}{y+z} $\frac{x+y}{y+z}$ \displaystyle \frac{x+y}{y+z} $\displaystyle \frac{x+y}{y+z}$ 根式 二次根式 \sqrt{表达式} n次根式 \sqrt[n]{表达式} 根号上没有横线 \surd{表达式} 被开方表达式字符高度不一致时，为使横线在同一水平线上，插入(\mathstruct) $\sqrt{a}+\sqrt{b}+\sqrt{c}$ \sqrt{a}+\sqrt{b}+\sqrt{c} $\sqrt{\mathstrut a}+\sqrt{\mathstrut b}+\sqrt{\mathstrut c}$ \sqrt{\mathstrut a}+\sqrt{\mathstrut b}+\sqrt{\mathstrut c} 求和、积分 求和 \sum_{k=1}^n求和项 积分 \int_a^b积分项 无穷级数 \infty \sum_{a=1}^n $\sum_{a=1}^nx$ \int_1^{10}x $\int_1^{10}x$ \sum_{k=1}^\infty \frac{x^n}{n!} =\int_0 ^\infty e^x $\sum_{k=1}^\infty \frac{x^n}{n!} =\int_0 ^\infty e^x$ 多行效果：$$\sum_{k=1}^\infty \frac{x^n}{n!} =\int_0 ^\infty e^x$$ 改变上下限位置： 强制在上下侧\limits 强制在左右侧\nolimits 行内在上下侧：\sum\limits_{n=0}^\infty x^n $\sum\limits_{n=0}^\infty x^n$ 行间在左右侧：$$\sum\nolimits_{n=0}^\infty x^n$$ $$\sum\nolimits_{n=0}^\infty x^n$$ 上下划线 上划线 \overline 下划线 \underline 上花括弧 \overbrace 下花括弧 \underbrace $\overline{\overline{a^2}+\underline{ab}+\bar{a}^3}$ $\overline{\overline{a^2}+\underline{ab}+\bar{a}^3}$ $\underbrace{a+\overbrace{b+\dots+b}^{m\mbox个}+c}_{20\mbox个}$ $\underbrace{a+\overbrace{b+\dots+b}^{m\mbox个}+c}_{20\mbox个}$ 数学符号 \leq $\leq$ \geq $\geq$ \sim $\sim$ \approx $\approx$ \in $\in$ \notin $\notin$ \neq $\neq$ \ll $\ll$ \gg $\gg$ 希腊字符 $\alpha$ \alpha $\beta$ \beta $\gamma,\Gamma$ \gamma,\Gamma $\delta,\Delta$ \delta,\Delta $\epsilon,\varepsilon$ \epsilon,\varepsilon $\eta$ \eta $\theta,\Theta,\vartheta$ \theta,\Theta,\vartheta $\iota$ \iota $\lambda$ \lambda $\mu$ \mu $\phi,\Phi,\varphi$ \phi,\Phi,\varphi $\psi,\Psi$ \psi,\Psi $\omega,\Omega$ \omega,\Omega]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[12306席别代码]]></title>
      <url>%2F12306%E5%B8%AD%E5%88%AB%E4%BB%A3%E7%A0%81.html</url>
      <content type="text"><![CDATA[在12306查询车票时，可从返回的JSON字符串得到车次、始发站、终点站、时间、余票数量等信息。其中有一个字段，其包含的字符串常见的有OM9,1413,OMO等。 这个字段代表该车次发售车票的席别，即硬卧、软卧、二等座、一等座等。 字符串中每一个字符代表一种席别： 1 硬座 2 软座 3 硬卧 4 软卧 6 高级软卧 9 商务座 F 动卧 M 一等座 O 二等座 P 特等座 无座的情况：若某个代码重复出现，则代表该席别出售无座票，如 OMO 表示二等座席位出售无座票 1413 表示硬座席位出售无座票 12306页面上还有一个席别为其他，可能的席位类型为软卧包厢，单人包厢等，可能的代码为H,F等（具体代表哪种席别我也没弄清楚）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TensorBoard说明文档]]></title>
      <url>%2FTensorBoard%E8%AF%B4%E6%98%8E%E6%96%87%E6%A1%A3.html</url>
      <content type="text"><![CDATA[TensorBoardTensorBoard是用来了解TensorFlow如何运行、展示图表的一套Web应用程序。 本文档介绍如何利用TensorBoard还嫌可视化，并给出TensorBoard的一些关键概念。更深入的例子请参见教程 TensorBoard: Visualizing Learning。要更深入了解图表可视化工具，请看教程TensorBoard: Graph Visualization。 还可以看这个视频教程，了解如何安装和使用TensorBoard。 使用方法在运行TensorBoard之前，确定已经生成并通过summary writer把训练摘要数据保存到文件夹中：1file_writer = tf.summary.FileWriter(&apos;/path/to/logs&apos;, sess.graph) 查看TensorBoard tutorial了解更多细节。当有了事件文件，指定其所在文件夹，就可以运行TensorBoard：1tensorboard --logdir=path/to/logs 执行上述命令后会显示TensorBoard已经启动的信息。现在可以访问http://localhost:6006。 TensorBoard从logdir中读入日志数据。若要了解TensorBoard的配置等信息，运行tensorboard --help TensorBoard可以在Chrome和Firefox浏览器中使用，其他浏览器可能会出现错误或其他性能问题。 关键概念摘要运算：TensorBoard如何从TensorFlow中获取数据使用TensorBoard的第一步是从运行中的TensorFlow程序中获取数据，这需要摘要运算(summary ops)，摘要操作像tf.matmul或tf.nn.relu等运算操作一样：接收Tensor、产生Tensor，在TensorFlow Graph中求值。但摘要运算有所不同的是：这些Tensor包含serialized protobufs(我理解为可以持久化的一些东西)，可以写入磁盘并在TensorBoard中展示。为了在TensorBoard中对记录的摘要数据可视化，需要对摘要计算求值，得到其结果并将其以摘要的形式写入磁盘。对FileWriter的详细解释和例子在教程中。 支持的摘要计算包括： tf.summary.scalar tf.summary.image tf.summary.audio tf.summary.text tf.summary.histogram 标签：对数据取名字进行摘要计算时，要对其取一个标签tag。这个标签是该计算所记录的数据的名字，而且用于在前端页面展示。Scalar和histogram面板通过标签来标记数据，通过层次化的标签名对数据分组。如果有很多标签的话，我们建议使用/对其分组。 事件文件和日志文件夹：TensorBoard如何读取数据Runs：对比模型不同的训练结果可视化数值面板（Scalar）柱状图面板（Histogram）统计分布面板（Distribution）图像面板（Image）声音面板（Audio）计算图展示（Graph Explorer）Embedding Projector文本面板（Text）常见问题TensorBoard不显示任何数据TensorBoard只显示一部分数据TensorBoard支持多线程或分布式的summary writer吗？数据重叠在一起如何处理ensorFlow程序重新启动的问题如何从TensorBoard导出数据可以重叠多个图表吗可以自己生成散点图吗（或其他自定义图表）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TensorFlow CNN 相关API]]></title>
      <url>%2FTensorFlow-CNN-%E7%9B%B8%E5%85%B3API.html</url>
      <content type="text"><![CDATA[tf.nn.conv2d123456789conv2d( input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None) 给定4维的输入和4维的过滤器Tensor，进行2卷积运算。 输入Tensor的形状为[batch,height,width,channels]，过滤器张量的形状为[filter_height, filter_width, in_channels, out_channels] 把过滤器转化为2-D，其形状为[filter_height * filter_width * in_channels, output_channels] 在图像中提取形状为[batch, out_height, out_width, filter_height * filter_width * in_channels]的Tensor 图像块向量和过滤器矩阵相乘 步长参数strides中，必须满足strides[0]=strides[3]=1。大多数情况下水平步长和垂直步长相等。 参数： input Tensor。维度的顺序由data-format确定。 filter Tensor。与input数据类型相同。形状是[filter_height, filter_width, in_channels, out_channels] strides 整数列表（长度为4的1-D Tensor）。每个维度滑动窗口的步长，维度的顺序由data-format确定。 padding 字符串：&quot;SAME&quot;或&quot;VALID&quot;。&quot;SAME&quot;是对输入的首尾补0，以满足每个滑动窗口的大小。&quot;VALID&quot;是丢弃末尾的数据。 use_cudnn_on_gpu 布尔值，默认为True。 data_format 可选&quot;NHWC&quot;或&quot;NCHW&quot;，默认为&quot;NHWC&quot; name 为这个操作取一个名字。 tf.nn.bias_add123456bias_add( value, bias, data_format=None, name=None) 这个函数的作用是将偏差项bias加到value上面。 这个操作是tf.add的一个特例。其中bias必须为1维，而value可以为任意维度。与tf.add不同的是，数据被量化的情况下，value和bias的类型可以不同。 参数： value Tensor。 bias 1维的Tensor。大小与value最后一维相同。类型也须与value相同，除非value被量化。 data_format &quot;NHWC&quot;或&quot;NCHW&quot;。 name 为这个操作取一个名字。 tf.nn.relu1234relu( features, name=None) 计算非线性激活函数max(features,0) 参数: features Tensor。 name 为这个操作取个名字 tf.nn.max_pool1234567 value, ksize, strides, padding, data_format=&apos;NHWC&apos;, name=None) 对输入数据进行最大池化 参数： value 4维Tensor，形状为[batch, height, width, channels]，类型为tf.float32 ksize 长度&gt;=4的整形列表。每个维度的窗口大小。 strides 长度&gt;=4的整形列表。每个维度的滑动步长。 padding &quot;SAME&quot;或&quot;VALID&quot;。输出形状为：output_height/output_width = (height/width - pool_size) stride + 1，&quot;SAME&quot;为向上取整，&quot;VALID&quot;为向下取整 tf.nn.lrn12345678lrn( input, depth_radius=None, bias=None, alpha=None, beta=None, name=None) 局部响应归一化 4维的inputTensor可以看做3维的1维向量（沿着最后一维），对每个向量归一化。计算公式为：12sqr_sum[a, b, c, d] = sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)output = input / (bias + alpha * sqr_sum) ** beta 参数: input Tensor depth_radius 默认为5 bias 默认为1.0 alpha 默认为1.0 beta 默认为0.5，指数项 name 为这个操作取个名字 tf.nn.sparse_softmax_cross_entropy_with_logits123456sparse_softmax_cross_entropy_with_logits( _sentinel=None, labels=None, logits=None, name=None) 计算logists和labels的稀疏softmax交叉熵。 用于度量互斥的离散分类任务（每个样本只属于一类）的概率误差，如CIFAR-10图像，每个图像只属于一类。 注意：这个操作接受未处理的输入，为了提高效率，函数内部对logits做了softmax运算。所以不要输入softmax后的数值，这会产生不正确的结果。 常见的情况，logits的形状为[batch_size, num_classes]，labels为[batch_size]。更高维度的也支持。 为了避免混淆，传递参数时需要带上参数名（如sparse_softmax_cross_entropy_with_logits(logits=logits,labels=labels) 参数： labels 形状为[d_0, d_1, ..., d_{r-1}]的Tensor（r为label的rank）。labels取值必须为[0, num_classes) logits 对数概率(?)，形状为[d_0, d_1, ..., d_{r-1}, num_classes] name 为操作取一个名字 tf.train.exponential_decay12345678exponential_decay( learning_rate, global_step, decay_steps, decay_rate, staircase=False, name=None) 对学习率应用指数衰减。 训练模型时，随着训练的进行，逐渐减小学习率是好的做法。这个函数对初始的学习率应用指数衰减方法。需要global_step作为参数计算衰减后的学习率。可以传递一个TensorFlow变量，每次训练对其加一。 函数计算方法：1ecayed_learning_rate = learning_rate * decay_rate ^ (global_step / decay_steps) 若staircase为True，global_step / decay_steps计算结果为整数，此时学习率呈阶梯状下降。 参数: learning_rate 标量，初始学习率 global_step 标量（整数），不能为负 decay_steps 标量（整数），必须为正 decay_rate 标量，衰减率 staircase 布尔。 tf.control_dependencies控制计算顺序 tf.train.ExponentialMovingAveragetf.train.ExponentialMovingAverage]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS安装TensorFlow]]></title>
      <url>%2FCentOS%E5%AE%89%E8%A3%85TensorFlow.html</url>
      <content type="text"><![CDATA[在CentOS6上安装TensorFlow1.2后，import tensorflow时出现以下问题：1ImportError: /lib64/libc.so.6: version `GLIBC_2.17&apos; not found 这个错误的原因是未安装2.17版本的glibc库。 而在CentOS上，使用yum install glibc命令，只能更新到2.12版本。需要手动下载编译安装。 glibc-2.17下载地址：https://ftp.gnu.org/gnu/glibc/glibc-2.17.tar.gz 下载glibc并解压缩12wget https://ftp.gnu.org/gnu/glibc/glibc-2.17.tar.gztar -xvf glibc-2.17.tar.gz 编译安装12345cd glibc-2.17mkdir buildcd build../configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/binmake &amp;&amp; make install 查看glibc共享库：1ll /lib64/libc.so.6 现libc.so.6已经软链接到2.17版本1lrwxrwxrwx 1 root root 12 7月 21 10:11 /lib64/libc.so.6 -&gt; libc-2.17.so 可以查看系统中可使用的glibc版本1strings /lib64/libc.so.6 |grep GLIBC_ 123456789101112131415161718192021GLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_2.13GLIBC_2.14GLIBC_2.15GLIBC_2.16GLIBC_2.17GLIBC_PRIVATE 现在应该就没问题了。 参考资料：Linux/CentOS 升级C基本运行库CLIBC的注意事项]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TensorFlow学习笔记：CIFAR-10 CNN]]></title>
      <url>%2FTensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9ACNN-CIFAR-10.html</url>
      <content type="text"><![CDATA[官方文档地址：Convolutional Neural Networks 概述CIFAR-10分类是机器学习中常见的标准问题。CIFAR-10分类目标是把32*32像素的RGB图像分为10类1airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. 目标建立一个小型的CNN用于图像识别，做到： 规范的组织神经网络的结构、训练和评估 为构建更大、更复杂的模型提供模板 选用CIFAR-10数据的原因，一方面它足够复杂，能符合TensorFlow处理大模型的能力；另一方面它数据量较小，训练迅速，可以用来做测试和实验。 重点CIFAR-10教程示范了一些重要的结构，可以用来在TensorFlow种设计大型的复杂的模型 核心计算部分：卷积（convolution）, 修正线性激活（rectified linear activation）, 最大池化（max pooling）, 局部响应归一化（local response normalization） 神经网络训练时行为的可视化，包括图像输入，损失，神经网络行为的分布和梯度等。 计算学到的参数的moving avearage，并在评估中使用以提高预测效果 实现学习率随时间增加而减少 预取队列：将磁盘延迟和高代价的图像预处理与模型分开 提供了多GPU训练的版本，实现了： 在多个GPU卡间并行训练 在多个GPU间共享变量、更新变量值 结构该模型是由卷积层和非线性层组成的多层的结构。这些层之后连接全连接层，最后是Softmax分类器。模型结构大致和Alex Krizhevsky提出的模型一致，前面几层略有不同。 这个模型在单个GPU上训练若干小时后，就能达到非常好的效果：86%正确率。模型由1068298个可学习的参数组成，对一个图像分类需要19.5M次乘加操作。 代码组织代码在models/tutorials/image/cifar10/ cifar10_input.py 读原始的二进制CIFAR-10数据 cifar10.py 建立模型 cifar10_train.py 在CPU或GPU上训练模型 cifar10_multi_gpu_train.py 在多GPU环境中训练模型 cifar10_eval.py 评估模型 CIFAR-10模型神经网络模型代码在cifar10.py中。全部的训练图包括765个操作。建立下面的模块，编写重用性高的图结构代码： 模型输入：inputs()和disorted_inputs()，为训练和评估读入、预处理图像数据 模型预测：inference() 对提供的图片进行分类 模型训练：loss()和train()，计算损失、梯度、更新变量、结果可视化 模型输入输入模块由inputs()和distorted_inputs()构成，两个函数读入CIFAR-10二进制数据，文件由固定字节长度的记录组成，所以使用tf.FixedLengthRecordReader 图像被处理成： 裁切为24*24像素，评估裁剪中间部分，训练时随机 近似白化处理，使模型对图片动态的范围变化不敏感 从磁盘中读图片需要相当长的处理时间，为避免其使训练时间变长，使用16个独立的线程读图片来填充TenorFlow队列。 模型预测预测部分的代码在inference()中，计算预测的得分（logits），这部分的代码组织如下： conv1 卷积、修正线性激活（rectified linear activation） pool1 最大池化 norm1 局部响应归一化 conv2 卷积、修正线性激活 norm2 局部响应归一化 pool2 最大池化 local3 带有“修正线性激活的”的全连接 local4 带有“修正线性激活的”的全连接 softmax_linear 线性变换，输出结果 下图由TensorBoard生成，展示预测部分的操作 练习：inference的输出是未归一化的logits，尝试使用tf.nn.softmax修改网络结构，使其返回归一化的预测结果 练习：inference中的模型结构和cuda-convnet中的CIFAR-10模型有些许的不同。其中，在Alex的原始模型中，最上几层是局部连接而非全连接。尝试修改网络结构，在最上层形成局部连接的结构。 模型训练训练多分类网络常用的方法是多项式逻辑回归，如softmax regression。Softmax回归对结果应用非线性的softmax，计算归一化的预测结果与one-hot编码标签的交叉熵。为了正则化，使学习的变量的权重逐渐减小。模型的目标函数是交叉熵损失和，和权重衰减项的和，在loss()函数中返回。 应用tf.summary.scalar，在TensorBoard中将这一过程展示： 使用标准的梯度下降算法来训练，学习率随时间变化呈指数衰减： train()中，通过计算梯度、更新学习变量（tf.train.GradientDescentOptimizer），使目标函数最小化。train()返回一个操作，这个操作中执行一批图像的计算，以训练和更新模型。 启动和训练模型让训练跑起来：1python cifar10_train.py 结果如下：12345678Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.2015-11-04 11:45:45.927302: step 0, loss = 4.68 (2.0 examples/sec; 64.221 sec/batch)2015-11-04 11:45:49.133065: step 10, loss = 4.66 (533.8 examples/sec; 0.240 sec/batch)2015-11-04 11:45:51.397710: step 20, loss = 4.64 (597.4 examples/sec; 0.214 sec/batch)2015-11-04 11:45:54.446850: step 30, loss = 4.62 (391.0 examples/sec; 0.327 sec/batch)2015-11-04 11:45:57.152676: step 40, loss = 4.61 (430.2 examples/sec; 0.298 sec/batch)2015-11-04 11:46:00.437717: step 50, loss = 4.59 (406.4 examples/sec; 0.315 sec/batch)... 每10步显示一次损失、训练速度。下面是一些提示： 第一批(batch)数据训练很慢，因为需要预处理线程读取20000张CIFAR图像，打乱顺序加入队列。 显示的损失是最近一批数据的平均损失，这个损失是交叉熵与权重衰减项之和 在Tesla K40c上得到显示的训练速度，如果用CPU训练，速度较慢。 练习：在实验时，第一步训练耗时太长。尝试减少填入队列的图像的数目。在cifar10_input.py中查找min_fraction_of_examples_in_queue cifar10_train.py周期性的以checkpoints files保存模型参数，但不评估模型。Checkpoints会在cifar10_eval.py中使用，用来预测模型性能。 如果读完了前面的步骤，现在可以训练CIFAR-10模型了。Congratulations! cifar10_train.py返回的文字中包含少量的模型训练的信息。我们需要更多的训练时的信息，包括： 损失是真实的在减小，还是只是噪声？ 为模型提供的图片是否合适？ 梯度、激活值、权重是否合理？ 学习率是多少 TensorBoard提供了这些功能。在cifar10_train.py中，通过tf.summary.FileWriter周期性的显示这些数据。 例如，可以观察激活值的分布和特征的稀疏程度：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TensorFlow学习笔记：CNN MNIST]]></title>
      <url>%2FTensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9ACNN-MNIST.html</url>
      <content type="text"><![CDATA[官方文档地址：A Guide to TF Layers: Building a Convolutional Neural Network 卷积神经网络卷积神经网络是图片识别任务最先进的模型。 CNN应用一系列filters在原始像素数据上，提取学习高级特征，模型使用这些特征来分类。 CNN组成 卷积层： 指定数量的卷积核。对图像的每个区域进行一系列数学计算，得到单一的值，作为特征。再使用ReLU作为激活函数，以引入非线性特征。 池化层：对卷积得到的特征再次降维以减少处理时间。常用max_pooling，对每个2*2区域保留最大啊值，丢弃其他值。 全连接层：对卷积层提取、池化层采样的特征进行分类。每个节点都和上一层的每个节点相连接。 CNN由一堆卷积模块组成，每个模块都有卷积层，后跟一池化层。 最后一个卷积模块包含一个或多个全连接层，用作分类。 最后一个全连接层中，每个类别有一个节点（使模型能预测所有类别），用softmax作为激活函数（所有softmax值和为1），每个softmax值可以解释为图像属于该类的概率。 斯坦福CNN课程资料http://cs231n.github.io/convolutional-networks/ 使用CNN构建MNIST分类器CNN结构 卷积层-1：32个5*5filter，ReLU激活函数 池化层-1：:2*2max pooling，步长2（使采样区域不重复） 卷积层-2：64个5*5filter, ReLu激活函数 池化层-2：2*2max pooling，步长2 全连接层-1：1024神经元，dropout率0.4（训练中0.4概率给定的元素被丢弃） 全连接层-2：10神经元，每个代表一类 使用tf.layers模块构建上述各类型的层 conv2d 2维卷积层，给定卷积核数量、大小、padding、激活函数作为参数 max_pooling2d 2维池化层（max_pooling），给定filter大小、步长作为参数 dense 全连接层，参数为神经元数量、激活函数 以上方法都接收tensor作为输入，然后输出一个处理后的tensor。可以直接使用返回值作为下一层的输入。 cnn_model_fn()cnn_mnist.py接受MNIST特征数据、标签、模型类型（TRAIN、EVAL、INFER）作为输入参数，配置CNN网络，返回预测结果、损失和训练步骤。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162def cnn_model_fn(features, labels, mode): &quot;&quot;&quot;Model function for CNN.&quot;&quot;&quot; # Input Layer input_layer = tf.reshape(features, [-1, 28, 28, 1]) # Convolutional Layer #1 conv1 = tf.layers.conv2d( inputs=input_layer, filters=32, kernel_size=[5, 5], padding=&quot;same&quot;, activation=tf.nn.relu) # Pooling Layer #1 pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2) # Convolutional Layer #2 and Pooling Layer #2 conv2 = tf.layers.conv2d( inputs=pool1, filters=64, kernel_size=[5, 5], padding=&quot;same&quot;, activation=tf.nn.relu) pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2) # Dense Layer pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64]) dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu) dropout = tf.layers.dropout( inputs=dense, rate=0.4, training=mode == learn.ModeKeys.TRAIN) # Logits Layer logits = tf.layers.dense(inputs=dropout, units=10) loss = None train_op = None # Calculate Loss (for both TRAIN and EVAL modes) if mode != learn.ModeKeys.INFER: onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10) loss = tf.losses.softmax_cross_entropy( onehot_labels=onehot_labels, logits=logits) # Configure the Training Op (for TRAIN mode) if mode == learn.ModeKeys.TRAIN: train_op = tf.contrib.layers.optimize_loss( loss=loss, global_step=tf.contrib.framework.get_global_step(), learning_rate=0.001, optimizer=&quot;SGD&quot;) # Generate Predictions predictions = &#123; &quot;classes&quot;: tf.argmax( input=logits, axis=1), &quot;probabilities&quot;: tf.nn.softmax( logits, name=&quot;softmax_tensor&quot;) &#125; # Return a ModelFnOps object return model_fn_lib.ModelFnOps( mode=mode, predictions=predictions, loss=loss, train_op=train_op) 上述代码使用tf.layers模块构建各个层，计算损失，配置训练步骤，并生成预测。 输入层对2维的图像数据构建卷积层和池化层需要输入的tensor的形状为[batch_size,image_width,image_height, channels] batch_size 梯度下降训练时子集大小 image_width 输入图像宽度 image_height 输入图像高度 channels 彩色图片为3（红绿蓝）,黑白图片为1（黑） MNIST数据为单色28*28像素，所以输入的shape为[batch_size, 28, 28, 1] 把输入转换为该shape，执行reshape 1input_layer = tf.reshape(features, [-1, 28, 28, 1]) 上面的batch_size为-1表示该维度不确定，由输入的features动态计算。这允许我们把batch_size当做可调整的超参数。例如：batch为5时，features包含3920 (52828)个值，shape为[5,28,28,1]，batch为100时，输入的值个数为78400 卷积层-1对输入层应用32个5*5的filter，并使用ReLU作为激活函数。可以使用conv2d()函数来创建这一层 123456conv1 = tf.layers.conv2d( inputs=input_layer, filters=32, kernel_size=[5, 5], padding=&quot;same&quot;, activation=tf.nn.relu) 输入的tensor的形状必须是[batch_size, image_width,image_height,channels],这样可以与输入层相连。 filters 卷积核数量 kernel_size 卷积核维度 padding 为”valid”或”same”。padding=”same”时，输出的tensor和输入tensor维度相同（边缘处补0）。没有padding的话，2828经过55卷积，会产生24*24的tensor activation 指定激活函数，这里使用ReLU（tf.nn.relu） 输出tensor的形状为[batch_size,28,28,32]，宽度和高度和原来相同，但经过32个卷积核卷积，现在有32个channels 池化层-1现在可以把第一个pooling层和上面创建好的卷积层连接。使用max_pooling2d()构建池化层 1pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2) inputs 输入tensor。形状为[batch_size, image_width, image_height, channels]。这里的输入为上一层的输出，形状是[batch_size, 28, 28, 32] pool_size max pool filter的大小（[width, height]），这里为[2,2] strides 步长的大小。2表示长和宽每2像素划分为一个子区域（2*2的filter使用strides=2，使子区域没有重叠）。也可设置其他大小，如[3,6] max_pooling2d()输入的tensor形状为[batch_size, 14, 14, 32]，2*2的filter把高度和宽度减少了50% 卷积层-2和池化层-2和前面一样，第二个卷积层和池化层使用conv2d()和max_pooling2d()。在这里，卷积层使用64个55卷积核，池化层的设置与前面一样（22的max pool，步长2） 12345678conv2 = tf.layers.conv2d( inputs=pool1, filters=64, kernel_size=[5, 5], padding=&quot;same&quot;, activation=tf.nn.relu)pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2) 第二层卷积层使用第一层池化层的输出pool1作为输入，输出h_conv2tensor，h_conv2的形状为[batch_size,14,14,64]，高和宽与pool1相同，使用64个卷积核，所以channel为64 第二层池化层的形状为[batch_size, 7, 7, 64]（高和宽再次减少50%） 全连接层接下来添加一层包含1024神经元，使用ReLU的dense层，对卷积/池化采样的特征进行分类。在连接该层前，需要把特征映射（feature map）变换形状，使其变为2维 1pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64]) -1表示batch_size维度不定，由输入的样本数量动态计算。每个样本有7764个特征（长度/宽度/channels）。现在pool2_flat的形状为[batch_size,3136] 使用dense()连接该dense层 1dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu) input 输入的tensor （展开的特征映射） units 神经元数量 activation 激活函数 为了提高模型效果，需要添加dropout regularization，使用tf.layers.dropout() 12dropout = tf.layers.dropout( inputs=dense, rate=0.4, training=mode == learn.ModeKeys.TRAIN) input输入的tensor（dense） rate dropout率：训练中40%的元素被随机丢弃 training 指定模型是否正在训练中。dropout只有在training=True时被启用。 Logits层神经网络最后一层是logits层，返回预测的原始值。该层有10个神经元（代表数字0-9）,使用线性激活函数（默认） 1logits = tf.layers.dense(inputs=dropout, units=10) 计算损失训练和评估模型时，需要定义损失函数来度量模型预测结果和真实值的差异。多分类问题（例如MNIST）中，交叉熵（cross entropy）是典型的损失度量。 12345678loss = Nonetrain_op = None# Calculate loss for both TRAIN and EVAL modesif mode != learn.ModeKeys.INFER: onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10) loss = tf.losses.softmax_cross_entropy( onehot_labels=onehot_labels, logits=logits) labels tensor包括一组样本的预测分类值，例如[1,9….]。为了计算交叉熵，需要将其变为one-hot编码： 123[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], ...] 使用tf.onehot()进行转换。 indices 输入，哪个位置变为one-hot值 depth 类别的数目 下面的代码生成one-hot tensor 1onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10) labels 中为0-9的数值（[1,9…]），将其转换为int类型。depth为10，因为有10个可能的目标类别。 使用tf.losses.softmax_cross_entropy()对logits层进行softmax，计算交叉熵，结果为标量tensor 12loss = tf.losses.softmax_cross_entropy( onehot_labels=onehot_labels, logits=logits) 设置训练步骤前面定义了CNN结构，现在设置训练步骤，以优化训练损失。使用tf.contrib.layers.optimize_loss(), 这里使用0.001学习率，并使用随机梯度下降（stochastic gradient descent）作为优化算法 1234567# Configure the Training Op (for TRAIN mode)if mode == learn.ModeKeys.TRAIN: train_op = tf.contrib.layers.optimize_loss( loss=loss, global_step=tf.contrib.framework.get_global_step(), learning_rate=0.001, optimizer=&quot;SGD&quot;) 预测logits层返回[batch_size, 10]的tensor，现将这些原始值转换为两种形式 预测的类别 各类别的概率例子中，预测的类别是返回的tensor中每行最大值对应的列，使用tf.argmax找到其索引 1tf.argmax(input=logits, axis=1) input 从该tensor中提取最大值 axis 从哪个维度提取（logits形状为[batch_size, 10]） 通过tf.nn.softmax()得到概率 1tf.nn.softmax(logits, name=&quot;softmax_tensor&quot;) 将输出整理为字典形式： 123456predictions = &#123; &quot;classes&quot;: tf.argmax( input=logits, axis=1), &quot;probabilities&quot;: tf.nn.softmax( logits, name=&quot;softmax_tensor&quot;)&#125; 现在，得到了predictions,loss,train_op，连同mode参数可以把它们返回。 123# Return a ModelFnOps objectreturn model_fn_lib.ModelFnOps( mode=mode, predictions=predictions, loss=loss, train_op=train_op) 训练和评估CNN MNIST模型加载训练集/测试集1234567def main(unused_argv): # Load training and eval data mnist = learn.datasets.load_dataset(&quot;mnist&quot;) train_data = mnist.train.images # Returns np.array train_labels = np.asarray(mnist.train.labels, dtype=np.int32) eval_data = mnist.test.images # Returns np.array eval_labels = np.asarray(mnist.test.labels, dtype=np.int32) 把训练集数据（55000图像的原始像素）和标签（0-9）以numpy arrays保存在train_data和train_lable中。相似的，保存10000数据和标签作为测试集。 创建EstimatorEstimator是TensorFlow用来进行高级模型训练、评价和预测的类。 123# Create the Estimatormnist_classifier = learn.Estimator( model_fn=cnn_model_fn, model_dir=&quot;/tmp/mnist_convnet_model&quot;) model_fn 指定训练/评估/预测的模型 model_dir 保存checkpoints的路径 Logging创建日志以跟踪训练过程。创建一个tf.train.LoggingTensorHook，会记录Softmax层计算出的概率 1234# Set up logging for predictions tensors_to_log = &#123;&quot;probabilities&quot;: &quot;softmax_tensor&quot;&#125; logging_hook = tf.train.LoggingTensorHook( tensors=tensors_to_log, every_n_iter=50) 将需要记录的tensors存入tensor_to_log字典，key作为日志中的标签，相应的值是指定tensor的名称（name属性） every_n_iter 每训练50步记录一次 训练模型1234567# Train the modelmnist_classifier.fit( x=train_data, y=train_labels, batch_size=100, steps=20000, monitors=[logging_hook]) x 训练数据 y 训练集标签 batch 每次训练样本数 steps 训练次数 monitors logging_hook 评估模型在MNIST测试集上评价训练好的模型。使用tf.contrib.learn.MetricSpec创建metrics字典来计算准确率 123456# Configure the accuracy metric for evaluationmetrics = &#123; &quot;accuracy&quot;: learn.MetricSpec( metric_fn=tf.metrics.accuracy, prediction_key=&quot;classes&quot;),&#125; metric_fn 计算metric的函数，这里使用预定义的tf.metrics.accuracy prediction_key 包含预测值的tensor的名称（前面定义过） 通过下面代码打印评估结果： 1234# Evaluate the model and print resultseval_results = mnist_classifier.evaluate( x=eval_data, y=eval_labels, metrics=metrics)print(eval_results) 运行模型结果显示如下 12345678910111213INFO:tensorflow:loss = 2.36026, step = 1INFO:tensorflow:probabilities = [[ 0.07722801 0.08618255 0.09256398, ...]]...INFO:tensorflow:loss = 2.13119, step = 101INFO:tensorflow:global_step/sec: 5.44132...INFO:tensorflow:Loss for final step: 0.553216.INFO:tensorflow:Restored model from /tmp/mnist_convnet_modelINFO:tensorflow:Eval steps [0,inf) for training step 20000.INFO:tensorflow:Input iterator is exhausted.INFO:tensorflow:Saving evaluation summary for step 20000: accuracy = 0.9733, loss = 0.0902271&#123;&apos;loss&apos;: 0.090227105, &apos;global_step&apos;: 20000, &apos;accuracy&apos;: 0.97329998&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[网络攻防实验(3)-逆向分析]]></title>
      <url>%2F%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2%E5%AE%9E%E9%AA%8C-3-%E9%80%86%E5%90%91%E5%88%86%E6%9E%90.html</url>
      <content type="text"><![CDATA[题目说明说明：该题目由CrackMee.exe一个文件组成。该文件是一个简单的小程序，请大家逆向该程序，找到正确的字符串，输入到程序后即为成功。 题目下载实验程序下载 使用工具 IDA pro 解题步骤 使用IDA pro F5查看反编译的程序代码。这段程序就是构造出一个字符串，输入正确的话，就输出”Key Right!”。构造过程如下：前5个字节从q中取得，第6到9字节通过x和ans获得，第10字节为’3’(ASCII码51)，第11字节为’y’(ASCII码121) 找到以上变量的值。q为DWORD型，每四字节取一个值，可得v5前5字节为”thi5_”这里可找到x的值。同理，可找到ans的值。 编写一个程序来构造目标字符串的第6-11字节，参照(1)中的代码。这里我选择用python来写运行结果为:即要输入的字符串为&quot;thi5_1s_K3y&quot; 实验结果]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[网络攻防实验(2)-缓冲区溢出]]></title>
      <url>%2F%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2%E5%AE%9E%E9%AA%8C-2-%E7%BC%93%E5%86%B2%E5%8C%BA%E6%BA%A2%E5%87%BA.html</url>
      <content type="text"><![CDATA[题目说明说明：该题目由memory、flag两个文件组成。memory为可执行代码，存在缓冲区溢出漏洞，请同学们分析该程序的二进制代码找到漏洞成因，并通过修改程序的执行流程导致任意代码执行漏洞将flag中的FLAG信息输出出来。单机执行：请同学们在自己的机器上运行脚本：./host，5555端口即为程序输入端口。如果编写exploit攻击成功，会出现以下提示：{FLAG:this is a flag} 题目下载实验程序下载 使用工具 IDA pro pwntools(python2.7) socat linux 解题步骤 使用IDA pro打开程序文件，按F5查看其反编译代码观察到mem_test()函数中调用了scanf()，可能造成缓冲区溢出。推测此题的解题思路为，scanf读入一定长度的字符，覆盖mem_test()的返回地址，导致任意代码执行。 寻找要执行的函数。打开函数视图，找到win_func()函数，这个函数直接调用了system(),可以传递参数为”cat flag”，从而显示flag文件中的内容。 使用IDA pro远程调试linux下的memory程序，在scanf()后添加断点。输入若干’0’后，观察栈变化。观察到栈地址0xFFB21C5C保存的正式mem_test()的返回地址，将其覆盖为win_func()的地址，即可跳转执行win_func()函数调用时，先将其返回地址入栈，再将参数入栈。0xFFB21C5C后面4字节为返回地址（可构造为任意可访问的地址）,再后面4字节为参数地址。 查看string视图，找到”cat flag”字符串，其地址为0x08048840。查看function视图，找到win_func()函数地址为0x08048610 构造payload为23字节字符+win_func地址+任意可访问地址+”cat flag”地址。使用pwntools编写exploit。 1234from pwn import *conn=remote('localhost',5555)conn.send('a'*23+p32(0x08048610)+p32(0x08048610)+p32(0x08048840))conn.interactive() 实验结果]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[网络攻防实验(1)-缓冲区溢出]]></title>
      <url>%2F%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2%E5%AE%9E%E9%AA%8C-1-%E7%BC%93%E5%86%B2%E5%8C%BA%E6%BA%A2%E5%87%BA.html</url>
      <content type="text"><![CDATA[题目说明说明：该题目由100、flag两个文件组成。100为可执行代码，存在缓冲区溢出漏洞。请同学们分析该程序的二进制代码找到漏洞成因，并通过修改程序的执行流程导致任意代码执行漏洞将flag中的FLAG信息输出出来。单机执行：请同学们在自己的机器上运行脚本：./host，9999端口即为程序输入端口。如果编写exploit攻击成功，会出现以下提示：{FLAG:this is a flag} 题目下载实验程序下载 使用工具 IDA pro pwntools (python2.7) socat 解题步骤 使用IDA pro打开程序，按F5可查看其反汇编代码。注意到scanf函数可能存在缓冲区溢出漏洞。推断此题的解题思路为：通过scanf函数输入一定长度的字符，覆盖栈中的v5()函数的地址。 寻找要执行函数的地址。打开函数视图(view-&gt;subview-&gt;function)，找到win()函数：执行这个函数可以读出flag文件中内容。 寻找溢出点。在scanf函数后添加断点，调试程序。在程序中输入若干个’0’后，栈信息如下：输入的’a’的ASCII码为0x30，栈中lose()函数的地址为12345674. 构造payload为 64字节字符+win()函数地址。本题中，执行host.sh脚本可将程序输入/输出重定向到9999端口,可使用pwntools编写exploit。```pythonfrom pwn import *conn=remote(&apos;localhost&apos;,9999)conn.send(&apos;a&apos;*64+p32(0x0804861B))conn.interactive() 实验结果]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[依法治国的发展及对当代大学生法治素养的探讨]]></title>
      <url>%2F%E4%BE%9D%E6%B3%95%E6%B2%BB%E5%9B%BD%E7%9A%84%E5%8F%91%E5%B1%95%E5%8F%8A%E5%AF%B9%E5%BD%93%E4%BB%A3%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B3%95%E6%B2%BB%E7%B4%A0%E5%85%BB%E7%9A%84%E6%8E%A2%E8%AE%A8.html</url>
      <content type="text"><![CDATA[摘要 本文阐述了依法治国的发展历程：从法治建设“十六字方针”到提出依法治国的基本方略；从依法治国被写入宪法，到提出全面推进依法治国。社会主义依法治国理论日益走向成熟，社会主义依法治国实践迈入更高阶段。最后，在总结依法治国的基础上，探讨了依法治国大背景下如何提高当代大学生的法制素养。 依法治国的发展历程 1954年制定了共和国第一部宪法，初步奠定了社会主义法制的基础。但在“文革”十年，社会主义法制遭到严重破坏。在党的十一届三中全会召开前的中央工作会议上，邓小平提出了“为了保障人民民主，必须加强法制，使民主制度化、法律化，做到有法可依，有法必依，执法必严，违法必究。”这段谈话，为我国依法治国基本方略的形成奠定了基本理论基础。 党的十一届三中全会确立了解放思想、实事求是的思想路线，同时提出了加强社会主义民主，健全社会主义法制的任务目标。会议公报[1]指出：“为了保障人民民主，必须加强社会主义法制，使民主制度化、法律化，使这种制度和法律具有稳定性、连续性和极大的权威，做到有法可依，有法必依，执法必严，违法必究。”这准确地描述了法治的基本精神内核，阐述了依法治国的基本内涵，为依法治国方略的最终提出奠定了思想基础。 在党的十一届三中全会精神指引下，在党的领导下我国进行了一系列重大立法工作。党的十一届三中全会以后，按照**“建设有中国特色的社会主义”和“以经济建设为中心”的方针和指导思想，立法进程被不断推进，先后制定了一系列重要的民事、经济法律，为改革开放和社会主义现代化建设提供了坚实的法律保障。 1989年，颁布行政诉讼法，是我国法治政府建设的重要开端。1993年，党的十四届三中全会通过的《决定》[2]提出：“各级政府都要依法行政，依法办事。”这是第一次在党的正式文件中提出“依法行政”，将法治政府建设作为法治建设的重点，进一步丰富了依法治国的内涵。此时，依法治国方略虽然尚未提出，但“十六字方针”和宪法及一系列重要法律的修订出台，清晰阐释了依法治国的基本精神，社会主义法制体系开始形成，这为依法治国方略的形成奠定了思想基础和制度基础。 党的十五大正式提出依法治国基本方略。十五大报告[3]中指出：“依法治国，是党领导人民治理国家的基本方略，是发展社会主义市场经济的客观需要，是社会文明进步的重要标志，是国家长治久安的重要保障。”这就正式将依法治国提升为国家治理的基本方略。依法治国方略的提出，是对我们党治国理政经验的全面总结与升华，标志着党在执政理念、领导方式上实现了一次历史性跨越，为我国此后的国家治理和社会治理指明了方向，具有里程碑意义。 1999年3月通过的宪法修正案[4]规定：“中华人民共和国实行依法治国，建设社会主义法治国家”。这正式将依法治国确立为宪法的基本原则，通过国家根本法对依法治国予以保障，使其有了宪法保障，也使“依法治国”这一基本方略有了长期性、稳定性的制度基础。 在党的十五大提出依法治国基本方略的基础上，党的十六大提出了坚持依法执政、不断提高执政能力的思想，要求不断改革和完善党的领导方式和执政方式，将民主、法治、人权建设从以往的“精神文明”范畴中独立出来，正式提出“政治文明”的概念，这就进一步丰富了依法治国的内涵，明晰了依法治国与其他治理方式的关系。党的十六大还提出“三统一”的法治原则，即“发展社会主义民主政治，最根本的是要把坚持党的领导、人民当家作主和依法治国有机统一起来”，这就确立了中国特色社会主义依法治国方略的根本原则。 十八大确立了依法治国的新任务和目标，即到2020年全面建成小康社会时，实现“依法治国基本方略全面落实，法治政府基本建成，司法公信力不断提高，人权得到切实尊重和保障。”这个战略目标与全面建成小康社会的目标同时提出，进一步凸显了依法治国的重要性。2014年10月，十八届四中全会的主题为“依法治国”，总结了依法治国的经验，研究了全面推进依法治国若干重大问题，对依法治国进行总体部署和全面规划。 在我们这样一个13亿多人口的发展中大国全面推进依法治国，是国家治理领域一场广泛而深刻的革命。全面推进依法治国，总目标是建设中国特色社会主义法治体系，建设社会主义法治国家。这就是，在中国共产党领导下，坚持中国特色社会主义制度，贯彻中国特色社会主义法治理论，形成完备的法律规范体系、高效的法治实施体系、严密的法治监督体系、有力的法治保障体系，形成完善的党内法规体系，坚持依法治国、依法执政、依法行政共同推进，坚持法治国家、法治政府、法治社会一体建设，实现科学立法、严格执法、公正司法、全民守法，促进国家治理体系和治理能力现代化。 对当代青年大学生的法治素养的探讨 党的十八届四中全会对全面推进依法治国战略做出了总部署，在《决定》[5]中提出了“把法治教育纳入国民教育体系，从青少年抓起”的要求和目标。高等学校是法治教育的重要场所，大学生是高素质青年群体的重要组成部分，是学法、守法、护法、用法的生力军，提升大学生的法制素养是实现全面依法治国方略的一个十分重要的部分。 大学生的综合素质发展不但要求有较高的文化素养、扎实的专业基础知识和较强的工作能力，还要有自觉的规则意识和法律观念。 树立宪法至上的观念，把遵守法律规范作为自己行为的首要标准，这是新时代对当代大学生素质结构的新要求，因此，提高大学生法治素养就成为了高校立德树人的重要内容。 全面建设小康社会所需要的不仅仅是高水平的科技人才，更需要思想政治素质高，具备一定法治素养的创新型复合型建设人才。只有加强大学生法治教育，提升法治素养， 才能够让他们意识到全面实施依法治国的重要性， 并成为一个懂法的社会主义建设者和接班人，才能够自觉拿起法律武器维护自身、他人以及国家的权益，才能在经济建设中、在法律框架内充分发挥自身优势，为全面建设小康社会作出贡献. 对于广大高校学生，只有他们的法治素养提升了，才能保证法治校园的建立，同样，也只有依法治校落到了实处，才能保证大学生法治教育内容与法治教育环境高度一致，从而有效提升大学生法治素养。 对于学校而言，只有各高校注重大学生法治素养的提升，形成大学生参与学校依法管理的良好氛围，使大学生能够积极参与制定、宣传、践行学校的各项规章制度，同时通过法治学习，做到知法、守法，懂得用法律武器维护自我权益，才能更好地保障高校教育的依法顺利实施。 通过建设校园法治文化可以潜移默化地提升大学生法治素养，让遵法守法意识在学校蔚然成风，让法治文化在师生心中落地生根。要充分利用校园新闻、校园报纸、学生社团以及新兴媒体等载体加大法治文化宣传，以学生喜闻乐见的形式宣传法治文化。还要将法治教育融入大学生教育中，融入学生社会实践中，在学生自我教育、自我管理、自我服务中体现和培养法治精神、法治思维等法治素养，达到内化于心、外化于行的效果。推进法治文化主题活动。搭建形式多样的法治文化主题活动，打造法治文化宣传教育活动品牌，让学生在活动中体验法治精神。 可以通过开展“国家宪法日”主题活动，让学生牢固树立公民权利与义务相统一的观念。通过开展“校园诚信教育”活动，使遵纪守法成为大学生的共同追求和自觉行动。 要探索法治文化长效机制。高校要注重将法治文化培育纳入学生成长成才的全过程，以制度形式规范法治文化建设的领导体制、运行机制、活动载体、队伍建设、考核管理、经费投入和硬件保障。要站在“四个全面”战略布局的高度，将通过法治文化熏陶提升大学生法治素养作为一项常抓不懈的工作，让法治精神在一代代大学生群体中传承和发扬。 参考文献 [1] 中国共产党第十一届中央委员会第三次全体会议公报[M]. 人民出版社, 1979. [2] 中共中央关于建立社会主义市场经济体制若干问题的决定[J]. 求实, 1993(12):1-13. [3] 江泽民. 高举邓小平理论伟大旗帜把建设有中国特色社会主义事业全面推向二十一世纪[M]. 人民出版社, 1997. [4] 中华人民共和国宪法修正案[C] 1999. [5] 中新网. 中共中央 关于全面推进依法治国若干重大问题的决定[M]. 中国法制出版社, 2014. [6] 李艳. 大学生法治教育[J]. 教育, 2015(35):210-210. [7] 李全文. 全面依法治国视域中的大学生法治教育[J]. 思想理论教育导刊, 2016(5).]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[网页设计作品]]></title>
      <url>%2F%E7%BD%91%E9%A1%B5%E8%AE%BE%E8%AE%A1%E4%BD%9C%E5%93%81.html</url>
      <content type="text"><![CDATA[女朋友的部分网页设计作品 教育年度盘点网页链接：尚未上线 数读中学专题-成都七中网页链接：数读中学系列专题—成都七中｜中国教育在线 新高三生规划网页链接：2017年高三生学习规划|高三规划|中国教育在线 2016国庆专题网页链接：已下线 高三你准备好了吗？网页链接：高三,你准备好了吗_中国教育在线 图解小升初网页链接：图解小升初：小升初过后，初中英语怎么学？]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[棋盘覆盖问题]]></title>
      <url>%2F%E6%A3%8B%E7%9B%98%E8%A6%86%E7%9B%96%E9%97%AE%E9%A2%98.html</url>
      <content type="text"><![CDATA[问题描述在一个2^k*2^k个方格组成的棋盘中，恰有一个方格与其他方格不同，称该方格为一特殊方格，如图所示，红色方格为特殊方格。 棋盘覆盖问题是指，要用下图中的四种不同形态的L型骨牌覆盖棋盘上除特殊方格以外的所有方格，且任何2个L型骨牌不能重叠覆盖。 解题思路采用分治法来求解此问题 若k=2，则直接用一个L型骨牌来覆盖非特殊方格 k&gt;3时，可把原棋盘分成四个2^(k-1)阶的子棋盘，特殊方格位于四个棋盘中的一个。其他三个子棋盘也可转化为特殊棋盘，做法是用一个L型骨牌覆盖三个子棋盘的连接处的三个方格，如图所示。此时原问题转化为4个小规模棋盘的覆盖问题，可递归求解。 算法 设置一个全局变量mark，用于记录骨牌的序号 如果边长为2，则将给定的特殊方格(x,y)用给定的序号标记，其他三个方格用mark标记。 如果边长&gt;2，则把棋盘分割为四部分，判断特殊方格所处的子棋盘。对于有特殊方格的棋盘，继续递归求解。对于其他3个子棋盘： 左上角的子棋盘：其右下角方格为“特殊方格” 右上角的子棋盘：其右下角方格为“特殊方格” 左下角的子棋盘：其右上角方格为“特殊方格” 右下角的子棋盘：其左上角方格为“特殊方格” 这三个子棋盘的假想的“特殊方格”用同一个骨牌覆盖（标记相同），继续递归处理。 Python语言实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081# coding=utf-8mark = 1list = []# 生成棋盘def initTable(n): global list; for i in range(n): row = [] for j in range(n): row.append(-1) list.append(row)# 检查特殊点区域def check(midx, midy, x, y): if x &lt; midx and y &lt; midy: return 0 # 左上 elif x &gt;= midx and y &gt;= midy: return 3 # 右下 elif x &gt;= midx and y &lt; midy: return 2 # 右上 else: return 1 # 左下# 覆盖x1~x2行，y1~y2列，特殊点为(x,y),用markX填充特殊点def cover(x1, x2, y1, y2, x, y, markX): global mark # 如果是2*2的格子 if x2 - x1 == 1: # 填充特殊点 list[x][y] = markX # 填充其他3个格子 for row in range(x1, x2 + 1): for col in range(y1, y2 + 1): if row != x or col != y: list[row][col] = mark mark += 1 return # 其他情况: 2*2以上的格子 # 用midx,midy把棋盘分为4部分 midx = (x1 + x2 + 1) / 2 midy = (y1 + y2 + 1) / 2 covered = &#123;0:False, 1:False, 2:False, 3:False&#125; # 检查特殊点在哪个区域 area = check(midx, midy, x, y) if area == 0: # 特殊格子在左上 cover(x1, midx - 1, y1, midy - 1, x, y, markX) if area == 1: # 特殊格子在右上 cover(x1, midx - 1, midy, y2, x, y, markX) if area == 2: # 特殊格子在左下 cover(midx, x2, y1, midy - 1, x, y, markX) if area == 3: # 特殊格子在右下 cover(midx, x2, midy, y2, x, y, markX) # 标记已经处理过的区域 covered[area] = True # 其他3个区域 取内角的三个小格子为特殊点 newMark = mark mark += 1 # 处理其他3个区域 if not covered[0]: cover(x1, midx - 1, y1, midy - 1, midx - 1, midy - 1, newMark) if not covered[1]: cover(x1, midx - 1, midy, y2, midx - 1, midy, newMark) if not covered[2]: cover(midx, x2, y1, midy - 1, midx, midy - 1, newMark) if not covered[3]: cover(midx, x2, midy, y2, midx, midy, newMark) def printTable(): global list for i in range(len(list)): row = "" for j in range(len(list)): row += (str(list[i][j]) + "\t") print(row+"\n")if __name__ == '__main__': n = 8 initTable(n) cover(0, 7, 0, 7, 2, 3, 0) printTable()]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Django环境搭建及简单的视图与网址的配置]]></title>
      <url>%2FDjango%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E7%AE%80%E5%8D%95%E7%9A%84%E8%A7%86%E5%9B%BE%E4%B8%8E%E7%BD%91%E5%9D%80%E7%9A%84%E9%85%8D%E7%BD%AE.html</url>
      <content type="text"><![CDATA[安装Django用pip安装Django：pip install Django 检查是否安装成功 python命令行下123import djangodjango.VERSION#django.get_version() 若能显示出版本信息，则安装成功 Django基本命令创建一个Django projectdjango-admin.py startproject project-name 创建apppython manage.py startapp app-name 启动测试服务器 python manage.py runserver 使用其他端口python manage.py runserver port 监听所有可用ip(内外网情况下)python manage.py runserver 0.0.0.0:port 视图和网址新建项目 “mysite”1django-admin.py startproject mysite 创建成功后，目录样式为: 1234567mysite├── manage.py└── mysite ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py 在外层mysite目录下，创建app “test”1python manage.py startapp test test下目录结构为:123456test/├── __init__.py├── admin.py├── models.py├── tests.py└── views.py 把新建的app “test” 加入到INSTALLED_APPS中vim mysite/mysite/settings.py修改INSTALLED_APPS123456789INSTALLED_APPS = ( &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &apos;test&apos;,) 定义视图函数修改mysite/test/views.py12345# coding:utf-8from django.http import HttpResponse def index(request): return HttpResponse(u"李博伟正在学习Django") 定义视图函数的URL修改mysite/mysite/urls.py12345678from django.conf.urls import urlfrom django.contrib import adminfrom learn import views as test_views # 修改这里 urlpatterns = [ url(r'^$', test_views.index), # 修改这里 url(r'^admin/', admin.site.urls),] 在url()中用正则表达式定义了网址的形式，和该网址对应的视图函数 运行python manage.py runserver查看效果]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[搭建shadowsocks服务器实现ipv6免费上网]]></title>
      <url>%2F%E6%90%AD%E5%BB%BAshadowsocks%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E7%8E%B0ipv6%E5%85%8D%E8%B4%B9%E4%B8%8A%E7%BD%91.html</url>
      <content type="text"><![CDATA[背景很多高校提供一定量的免费流量，超过之后就要付费。但是ipv6的流量不需要付费。可以通过shadowsocks搭建一个走ipv6流量的代理，从而实现免费上网。 所需要的工具shadowsocks、支持ipv6的VPS 支持ipv6的VPS我推荐Conoha，我一直在用，百兆带宽、SSD、不限流量、基本配置900日元/月，可以支付宝付款，总之优点很多。链接如下Conoha主机 shadowsocks的安装和一些配置可以参考Shadowsocks 使用说明科学上网之 Shadowsocks 安装及优化加速 IPv6 shadowsocks配置服务端配置若按照上面的链接中的方法安装shadowsocks，其配置文件路径为/etc/shadowsocks.json 修改配置文件123456789&#123; &quot;server&quot;:&quot;::&quot;, &quot;server_port&quot;:8989, &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;你的密码&quot;, &quot;timeout&quot;:600, &quot;method&quot;:&quot;aes-256-cfb&quot;&#125; 与ipv4的不同之处为&quot;sever&quot;:&quot;::&quot;，如此修改即可启用ipv6 启动shadowsocks服务1ssserver -c /etc/shadowsocks.json -d start 客户端配置客户端配置见下图，在服务器地址处填写服务器的ipv6地址]]></content>
    </entry>

    
  
  
</search>
